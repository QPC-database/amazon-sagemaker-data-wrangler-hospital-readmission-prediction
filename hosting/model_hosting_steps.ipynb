{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon SageMaker Model Deployment using persistent endpoint for Real-Time inference\n",
    "\n",
    "In this notebook we will depoy the Model that was trained using the preprocessed training_input from Data Wranger preprocessing Job.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform model deployment using Amazon SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import time\n",
    "from sagemaker import get_execution_role, session\n",
    "from time import gmtime, strftime\n",
    "from sagemaker.model import Model\n",
    "from sagemaker.image_uris import retrieve\n",
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "\n",
    "# Setup defaults\n",
    "region= boto3.Session().region_name\n",
    "role = get_execution_role()\n",
    "\n",
    "# Update this model_url with the trained model generated from training job that we ran as part of Data Wrangler\n",
    "model_url = '<<Your S3 location of pre-trained model artifact>>'\n",
    "\n",
    "# Pull the Amazon SageMaker built-in algorithm for xgboost\n",
    "image_uri = retrieve('xgboost', region, '1.2-1')\n",
    "# Create a model object using Model class\n",
    "model = Model(image_uri=image_uri, model_data=model_url, role=role)\n",
    "\n",
    "endpoint_name = 'DEMO-xgb-readmission-prediction-' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "print(\"EndpointName={}\".format(endpoint_name))\n",
    "\n",
    "# Deploy the model as an endpoint hosted by Amazon SageMaker\n",
    "hosted_endpoint = model.deploy(initial_instance_count=1,\n",
    "                instance_type='ml.m4.xlarge',\n",
    "                endpoint_name=endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform inference against the deployed model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SageMaker Predictor object to pass in the test data for inference\n",
    "predictor = Predictor(endpoint_name=endpoint_name, serializer=CSVSerializer())\n",
    "\n",
    "print(\"Sending test traffic to the endpoint {}. \\nPlease wait...\".format(endpoint_name))\n",
    "\n",
    "with open(\"test_data/test_data_UCI_sample.csv\", 'r') as f:\n",
    "    for row in f:\n",
    "        payload = row.rstrip('\\n')\n",
    "        print('Incoming Payload => ', payload)\n",
    "        response = predictor.predict(data=payload).decode('utf-8')\n",
    "        print(\"Inference Output => \", response)\n",
    "        time.sleep(1)\n",
    "        \n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
